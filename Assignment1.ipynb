{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Deep Learning Assignemnt 1\n",
        "####Aditya Karthully\n",
        "####a1899982"
      ],
      "metadata": {
        "id": "V3sUIeS9tLXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "HgQnNBgbtXYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zQpQgI4wSYtl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load Data"
      ],
      "metadata": {
        "id": "8_Vzkvy1taMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_svmlight_file('data.csv')\n",
        "X = X.toarray()"
      ],
      "metadata": {
        "id": "o-0RcwNHSdqL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X shape: {X.shape}')\n",
        "print(f'y shape: {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I187kYUetj1N",
        "outputId": "2aa7a695-2b5f-4a5e-e4d0-f6dafec02956"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (768, 8)\n",
            "y shape: (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Standardize Features"
      ],
      "metadata": {
        "id": "-vWxtP0TtqTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Y1RMSVyxSmj9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Split Data"
      ],
      "metadata": {
        "id": "JM_CbAnHtw-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b4nhFGNKtyq8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
        "print(f'Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkbKAHI-t1M8",
        "outputId": "1e14c84c-30be-41e8-f86f-ec2453d364e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (614, 8), Training labels shape: (614,)\n",
            "Test data shape: (154, 8), Test labels shape: (154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Traditional Perceptron Implementation"
      ],
      "metadata": {
        "id": "U9VIw8get6AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicPerceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=100):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.bias = 0\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def activation(self, x):\n",
        "        return np.where(x >= 0, 1, -1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation(linear_output)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation(linear_output)\n",
        "                # Perceptron update rule\n",
        "                if y[idx] != y_predicted:\n",
        "                    self.weights += self.lr * y[idx] * x_i\n",
        "                    self.bias += self.lr * y[idx]\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                predictions = self.predict(X)\n",
        "                accuracy = accuracy_score(y, predictions)\n",
        "                print(f'Epoch {epoch+1}/{self.epochs}, Training Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "unqrngYsSpah"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "input_size = X_train.shape[1]\n",
        "basic_perceptron = BasicPerceptron(input_size, learning_rate=0.1, epochs=100)\n",
        "basic_perceptron.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyaUelduCE5",
        "outputId": "350e2840-3d58-4341-aa87-5c3c7dd263b1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Training Accuracy: 74.76%\n",
            "Epoch 20/100, Training Accuracy: 70.85%\n",
            "Epoch 30/100, Training Accuracy: 69.22%\n",
            "Epoch 40/100, Training Accuracy: 73.78%\n",
            "Epoch 50/100, Training Accuracy: 72.64%\n",
            "Epoch 60/100, Training Accuracy: 72.15%\n",
            "Epoch 70/100, Training Accuracy: 74.10%\n",
            "Epoch 80/100, Training Accuracy: 72.64%\n",
            "Epoch 90/100, Training Accuracy: 71.50%\n",
            "Epoch 100/100, Training Accuracy: 72.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_pred_basic = basic_perceptron.predict(X_test)"
      ],
      "metadata": {
        "id": "PzdnJW5WuGHN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_basic = accuracy_score(y_test, y_pred_basic)\n",
        "print(f'\\nTest Accuracy with Basic Perceptron: {accuracy_basic * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_basic, target_names=['-1 (Non-Diabetic)', '+1 (Diabetic)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzMvcd-UuIdh",
        "outputId": "7f2d1db4-5251-4867-c1c6-d5bc826f6f6b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy with Basic Perceptron: 80.52%\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "-1 (Non-Diabetic)       0.80      0.60      0.69        55\n",
            "    +1 (Diabetic)       0.81      0.92      0.86        99\n",
            "\n",
            "         accuracy                           0.81       154\n",
            "        macro avg       0.81      0.76      0.77       154\n",
            "     weighted avg       0.81      0.81      0.80       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm_basic = confusion_matrix(y_test, y_pred_basic)\n",
        "sns.heatmap(cm_basic, annot=True, fmt=\"d\", cmap='Blues', xticklabels=['-1', '+1'], yticklabels=['-1', '+1'])\n",
        "plt.title('Confusion Matrix - Basic Perceptron')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "sItjSaaXuK1U",
        "outputId": "270e9ba3-4825-45c4-81b4-bb5868013166"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Enhanced Perceptron Implementation"
      ],
      "metadata": {
        "id": "wK410S5fuO_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidPerceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.01, epochs=1000, lambda_=0.01):\n",
        "        self.weights = np.random.randn(input_size) * 0.01\n",
        "        self.bias = 0\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def activation(self, x):\n",
        "        # Sigmoid activation function\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation(linear_output)\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        # L2 regularization\n",
        "        m = len(y_true)\n",
        "        loss = - (1/m) * np.sum(\n",
        "            y_true * np.log(y_pred + 1e-15) + (1 - y_true) * np.log(1 - y_pred + 1e-15)\n",
        "        ) + (self.lambda_ / (2*m)) * np.sum(np.square(self.weights))\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        for epoch in range(self.epochs):\n",
        "            y_pred = self.predict(X)\n",
        "\n",
        "\n",
        "            dw = (1/m) * np.dot(X.T, (y_pred - y)) + (self.lambda_/m) * self.weights\n",
        "            db = (1/m) * np.sum(y_pred - y)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                loss = self.compute_loss(y, y_pred)\n",
        "                y_pred_class = np.where(y_pred >= 0.5, 1, 0)\n",
        "                train_accuracy = accuracy_score(y, y_pred_class)\n",
        "                print(f'Epoch {epoch+1}/{self.epochs}, Loss: {loss:.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "Qf_xxqe5SrlT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust labels -> (0 and 1 instead of -1 and +1)\n",
        "y_sigmoid = np.where(y == -1, 0, 1)"
      ],
      "metadata": {
        "id": "-uwnDxp7udc_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split new data\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y_sigmoid, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AkJCrf1MugtV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "input_size = X_train_s.shape[1]\n",
        "sigmoid_perceptron = SigmoidPerceptron(input_size, learning_rate=0.1, epochs=1000, lambda_=0.1)\n",
        "sigmoid_perceptron.fit(X_train_s, y_train_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFPahdKujLY",
        "outputId": "e82f3c32-10ff-4e15-e527-42a31ca8a229"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000, Loss: 0.4804, Training Accuracy: 76.87%\n",
            "Epoch 200/1000, Loss: 0.4703, Training Accuracy: 76.55%\n",
            "Epoch 300/1000, Loss: 0.4685, Training Accuracy: 76.71%\n",
            "Epoch 400/1000, Loss: 0.4681, Training Accuracy: 76.87%\n",
            "Epoch 500/1000, Loss: 0.4681, Training Accuracy: 77.04%\n",
            "Epoch 600/1000, Loss: 0.4680, Training Accuracy: 77.04%\n",
            "Epoch 700/1000, Loss: 0.4680, Training Accuracy: 77.04%\n",
            "Epoch 800/1000, Loss: 0.4680, Training Accuracy: 77.04%\n",
            "Epoch 900/1000, Loss: 0.4680, Training Accuracy: 77.04%\n",
            "Epoch 1000/1000, Loss: 0.4680, Training Accuracy: 77.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_pred_prob = sigmoid_perceptron.predict(X_test_s)\n",
        "y_pred_sigmoid = np.where(y_pred_prob >= 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "ZtYo3zK_umHa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy_sigmoid = accuracy_score(y_test_s, y_pred_sigmoid)\n",
        "print(f'\\nTest Accuracy with Sigmoid Perceptron: {accuracy_sigmoid * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_sigmoid, target_names=['0 (Non-Diabetic)', '1 (Diabetic)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNkXJ8O3uoWZ",
        "outputId": "13870d24-cdf9-49a5-a4b9-4eafc1a8769b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy with Sigmoid Perceptron: 75.32%\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "0 (Non-Diabetic)       0.65      0.67      0.66        55\n",
            "    1 (Diabetic)       0.81      0.80      0.81        99\n",
            "\n",
            "        accuracy                           0.75       154\n",
            "       macro avg       0.73      0.74      0.73       154\n",
            "    weighted avg       0.76      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm_sigmoid = confusion_matrix(y_test_s, y_pred_sigmoid)\n",
        "sns.heatmap(cm_sigmoid, annot=True, fmt=\"d\", cmap='Greens', xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
        "plt.title('Confusion Matrix - Sigmoid Perceptron')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "GfDnaOtauquv",
        "outputId": "d341de3d-e3d1-4fd4-f8e7-1c047037d129"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHHCAYAAADqJrG+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDAUlEQVR4nO3de3zP9f//8ft7s703Zid2dBghhqhGLEkONZLIEPWpOVTUkE0pnz7lmIkKJae+wqcPEpV0csgxNRGRJDlFxeZQm1Pem+31+6OL96+3bWxv79fe8+527fK6XOz5er6fr8frva093o/n8/V6WQzDMAQAAOAEL3cHAAAArl0kEgAAwGkkEgAAwGkkEgAAwGkkEgAAwGkkEgAAwGkkEgAAwGkkEgAAwGkkEgAAwGkkEv9Qe/fu1V133aWgoCBZLBYtXbrUpeP//PPPslgsmjt3rkvHvZbdcccduuOOO9wdxmXNnTtXFotFP//8s7tDuawaNWqod+/eV+x3rZwPcC0jkXCj/fv3q3///rruuuvk5+enwMBAtWjRQlOmTNGff/5p6rGTkpK0c+dOvfjii3r77bfVpEkTU49Xmnr37i2LxaLAwMBC38e9e/fKYrHIYrHo5ZdfLvH4R44c0ciRI7V9+3YXRFs6cnJyNGXKFN10000KDAxUcHCwGjRooMcee0w//viju8Nzu5EjR9p/JiwWi8qXL6/69evrP//5j06dOuXu8K7aV199pZEjRyorK8vdocADlXN3AP9Un3zyibp37y6r1aqHH35YDRs2VE5OjjZu3Kinn35au3bt0qxZs0w59p9//qn09HQ999xzGjhwoCnHiImJ0Z9//ikfHx9Txr+ScuXK6dy5c/roo4/Uo0cPh33z58+Xn5+fzp8/79TYR44c0ahRo1SjRg3deOONxX7dypUrnTqeKyQmJuqzzz5Tr1699Oijjyo3N1c//vijPv74Y916662qV6+eJOmhhx5Sz549ZbVa3RZrcezZs0deXq7/HDR9+nQFBATozJkzWrlypV588UWtWbNGX375pSwWi8uPV1q++uorjRo1Sr1791ZwcLC7w4GHIZFwg4MHD6pnz56KiYnRmjVrFBUVZd+XnJysffv26ZNPPjHt+MePH5ckU/+HYrFY5OfnZ9r4V2K1WtWiRQstXLiwQCKxYMECdezYUe+9916pxHLu3DmVL19evr6+pXK8S23ZskUff/yxXnzxRf373/922Dd16lSHT6ne3t7y9vYu5QhLzqxEp1u3bqpcubIkacCAAUpMTNT777+vTZs2KT4+3ulxDcPQ+fPn5e/v76pQTZOfn6+cnBy3/v7i2sLUhhtMmDBBZ86c0ezZsx2SiItq166tJ5980v71hQsXNGbMGNWqVUtWq1U1atTQv//9b9lsNofX1ahRQ/fcc482btyoW265RX5+frruuuv03//+195n5MiRiomJkSQ9/fTTslgsqlGjhqS/pgQu/vvvLpZ9/27VqlW67bbbFBwcrICAANWtW9fhj1RRayTWrFmjli1bqkKFCgoODlbnzp21e/fuQo+3b98++yeooKAg9enTR+fOnSv6jb3EAw88oM8++8zhD+WWLVu0d+9ePfDAAwX6//7773rqqad0ww03KCAgQIGBgerQoYN27Nhh77Nu3To1bdpUktSnTx97Kfzied5xxx1q2LChtm7dqttvv13ly5e3vy+XrpFISkqSn59fgfNPSEhQSEiIjhw5UuxzvZz9+/dLklq0aFFgn7e3typVqmT/urA1Bfn5+Ro5cqSio6NVvnx5tW7dWj/88EOBdQoXX7tx40YNHjxYYWFhCg4OVv/+/ZWTk6OsrCw9/PDDCgkJUUhIiIYNG6ZLHz589uxZDR06VNWqVZPValXdunX18ssvF+hX2BqJXbt2qU2bNvL391fVqlU1duxY5efnO/mu/aVNmzaS/kr+L74XkydPVoMGDeTn56eIiAj1799ff/zxR4H47rnnHq1YsUJNmjSRv7+/Zs6cKUnKyspSSkqKatSoIavVqqpVq+rhhx/WiRMn7K+32WwaMWKEateuLavVqmrVqmnYsGEFfuctFosGDhyo+fPnq27duvLz81NcXJw2bNhg7zNy5Eg9/fTTkqSaNWvaf2Yvfo//PkaDBg1ktVq1fPlySdK3336rDh06KDAwUAEBAWrbtq02bdrkEMPF7/uXX36p1NRUhYWFqUKFCrrvvvvsH1rg2ahIuMFHH32k6667Trfeemux+j/yyCOaN2+eunXrpqFDh+rrr79WWlqadu/erQ8++MCh7759+9StWzf169dPSUlJeuutt9S7d2/FxcWpQYMG6tq1q4KDg5WSkqJevXrp7rvvVkBAQIni37Vrl+655x41atRIo0ePltVq1b59+/Tll19e9nWff/65OnTooOuuu04jR47Un3/+qddff10tWrTQtm3bCiQxPXr0UM2aNZWWlqZt27bp//7v/xQeHq6XXnqpWHF27dpVAwYM0Pvvv6++fftK+qsaUa9ePd18880F+h84cEBLly5V9+7dVbNmTWVmZmrmzJlq1aqVfvjhB0VHRys2NlajR4/WCy+8oMcee0wtW7aUJIfv5cmTJ9WhQwf17NlT//rXvxQREVFofFOmTNGaNWuUlJSk9PR0eXt7a+bMmVq5cqXefvttRUdHF+s8r+Ri4jh//ny1aNFC5cqV7Nd++PDhmjBhgjp16qSEhATt2LFDCQkJRU4NDRo0SJGRkRo1apQ2bdqkWbNmKTg4WF999ZWqV6+ucePG6dNPP9XEiRPVsGFDPfzww5L++tR+7733au3aterXr59uvPFGrVixQk8//bR+++03TZo0qcgYMzIy1Lp1a124cEHPPvusKlSooFmzZl11BeBiEnYx2erfv7/mzp2rPn36aPDgwTp48KCmTp2qb7/9Vl9++aXDVN6ePXvUq1cv9e/fX48++qjq1q2rM2fOqGXLltq9e7f69u2rm2++WSdOnNCyZcv066+/qnLlysrPz9e9996rjRs36rHHHlNsbKx27typSZMm6aeffiqwMHr9+vVatGiRBg8eLKvVqmnTpql9+/bavHmzGjZsqK5du+qnn37SwoULNWnSJHvFJSwszD7GmjVr9O6772rgwIGqXLmyatSooV27dqlly5YKDAzUsGHD5OPjo5kzZ+qOO+7Q+vXr1axZM4c4Bg0apJCQEI0YMUI///yzJk+erIEDB2rRokVX9T3ANcBAqcrOzjYkGZ07dy5W/+3btxuSjEceecSh/amnnjIkGWvWrLG3xcTEGJKMDRs22NuOHTtmWK1WY+jQofa2gwcPGpKMiRMnOoyZlJRkxMTEFIhhxIgRxt9/VCZNmmRIMo4fP15k3BePMWfOHHvbjTfeaISHhxsnT560t+3YscPw8vIyHn744QLH69u3r8OY9913n1GpUqUij/n386hQoYJhGIbRrVs3o23btoZhGEZeXp4RGRlpjBo1qtD34Pz580ZeXl6B87Barcbo0aPtbVu2bClwbhe1atXKkGTMmDGj0H2tWrVyaFuxYoUhyRg7dqxx4MABIyAgwOjSpcsVz7Ek8vPz7XFFREQYvXr1Mt544w3j0KFDBfrOmTPHkGQcPHjQMAzDyMjIMMqVK1cgppEjRxqSjKSkpAKvTUhIMPLz8+3t8fHxhsViMQYMGGBvu3DhglG1alWH92Pp0qX29+LvunXrZlgsFmPfvn32tpiYGIdjDxkyxJBkfP311/a2Y8eOGUFBQQ7nU5SLP3N79uwxjh8/bhw8eNCYOXOmYbVajYiICOPs2bPGF198YUgy5s+f7/Da5cuXF2i/+Lu4fPlyh74vvPCCIcl4//33C8Rw8T17++23DS8vL+OLL75w2D9jxgxDkvHll1/a2yQZkoxvvvnG3nbo0CHDz8/PuO++++xtEydOLPJ9kGR4eXkZu3btcmjv0qWL4evra+zfv9/eduTIEaNixYrG7bffbm+7+H1v166dw/c9JSXF8Pb2NrKysgocE56FqY1SdnEFeMWKFYvV/9NPP5UkpaamOrQPHTpUkgqspahfv779U7L016eOunXr6sCBA07HfKmLays+/PDDYpeOjx49qu3bt6t3794KDQ21tzdq1Eh33nmn/Tz/bsCAAQ5ft2zZUidPnizRKvoHHnhA69atU0ZGhtasWaOMjIxCpzWkv+bdLy7gy8vL08mTJ+3TNtu2bSv2Ma1Wq/r06VOsvnfddZf69++v0aNHq2vXrvLz87OXwF3FYrFoxYoVGjt2rEJCQrRw4UIlJycrJiZG999//2VX8q9evVoXLlzQE0884dA+aNCgIl/Tr18/h6mwZs2ayTAM9evXz97m7e2tJk2aOPxcfvrpp/L29tbgwYMdxhs6dKgMw9Bnn31W5DE//fRTNW/eXLfccou9LSwsTA8++GCRrylM3bp1FRYWppo1a6p///6qXbu2PvnkE5UvX16LFy9WUFCQ7rzzTp04ccK+xcXFKSAgQGvXrnUYq2bNmkpISHBoe++999S4cWPdd999BY598T1bvHixYmNjVa9ePYfjXJxmufQ48fHxiouLs39dvXp1de7cWStWrFBeXl6xzrtVq1aqX7++/eu8vDytXLlSXbp00XXXXWdvj4qK0gMPPKCNGzcW+D187LHHHL7vLVu2VF5eng4dOlSsGHDtIpEoZYGBgZKk06dPF6v/oUOH5OXlpdq1azu0R0ZGKjg4uMAvafXq1QuMERISUmAO92rcf//9atGihR555BFFRESoZ8+eevfddy+bVFyMs27dugX2xcbG6sSJEzp79qxD+6XnEhISIkklOpe7775bFStW1KJFizR//nw1bdq0wHt5UX5+viZNmqQ6derIarWqcuXKCgsL03fffafs7OxiH7NKlSolWlj58ssvKzQ0VNu3b9drr72m8PDwK77m+PHjysjIsG9nzpy5bH+r1arnnntOu3fv1pEjR7Rw4UI1b97cXs4uysXv26XvWWhoqP37calLv29BQUGSpGrVqhVo//v38tChQ4qOji6QZMfGxjrEUlScderUKdBe2M/b5bz33ntatWqV1q1bp3379un777+3/5Heu3evsrOzFR4errCwMIftzJkzOnbsmMNYNWvWLDD+/v371bBhw8vGsHfvXu3atavAMa6//npJKnCcws77+uuv17lz54q9RuHSWI8fP65z584V+fuan5+vX375xaHdFb+vuDaxRqKUBQYGKjo6Wt9//32JXlfcS8+KWnFvXLJYrSTHuPRTjb+/vzZs2KC1a9fqk08+0fLly7Vo0SK1adNGK1eudNmq/6s5l4usVqu6du2qefPm6cCBAxo5cmSRfceNG6fnn39effv21ZgxYxQaGiovLy8NGTKkRIv2Sjov/+2339r/OOzcuVO9evW64muaNm3q8Id1xIgRlz23v4uKilLPnj2VmJioBg0a6N1339XcuXNLvHaiKEV93wprL8n3sjTcfvvt9jUEl8rPz1d4eLjmz59f6P6/rzmQSv5z8Pfj3HDDDXr11VcL3X9pQuYKrriaxBW/r7g2kUi4wT333KNZs2YpPT39ipeUxcTEKD8/X3v37rV/MpOkzMxMZWVl2RfSuUJISEihZe7CPgl6eXmpbdu2atu2rV599VWNGzdOzz33nNauXat27doVeh7SXwvQLvXjjz+qcuXKqlChwtWfRCEeeOABvfXWW/Ly8lLPnj2L7LdkyRK1bt1as2fPdmjPyspy+OPiyvsJnD17Vn369FH9+vV16623asKECbrvvvvsV4YUZf78+Q432/p7+bm4fHx81KhRI+3du1cnTpxQZGRkgT4Xv2/79u1z+NR68uRJl3/SjImJ0eeff67Tp087VCUu3jDrcj/rMTEx2rt3b4H2wn7enFWrVi19/vnnatGihdN/eGvVqnXFDxG1atXSjh071LZt22L9rBV23j/99JPKly9vT25K+jMbFham8uXLF/n76uXlZUpCg2sTUxtuMGzYMFWoUEGPPPKIMjMzC+zfv3+/pkyZIumv0rwkTZ482aHPxU8rHTt2dFlctWrVUnZ2tr777jt729GjRwtcGfL7778XeO3FGzNdennaRVFRUbrxxhs1b948h2Tl+++/18qVK+3naYbWrVtrzJgxmjp1aqF/LC/y9vYu8Olp8eLF+u233xzaLiY8rrhL4DPPPKPDhw9r3rx5evXVV1WjRg0lJSUV+T5e1KJFC7Vr186+XS6R2Lt3rw4fPlygPSsrS+np6QoJCSnwafqitm3bqly5cpo+fbpD+9SpU4txdiVz9913Ky8vr8DYkyZNksViUYcOHS772k2bNmnz5s32tuPHjxdZPXBGjx49lJeXpzFjxhTYd+HChWL9PCQmJmrHjh0Ffqek///JvUePHvrtt9/05ptvFujz559/FpgCTE9Pd1jD88svv+jDDz/UXXfdZa8SlPRn1tvbW3fddZc+/PBDh0uBMzMztWDBAt122232aVqAioQb1KpVSwsWLND999+v2NhYhztbfvXVV1q8eLH9GvnGjRsrKSlJs2bNUlZWllq1aqXNmzdr3rx56tKli1q3bu2yuHr27KlnnnlG9913nwYPHqxz585p+vTpuv766x3+RzV69Ght2LBBHTt2VExMjI4dO6Zp06apatWquu2224ocf+LEierQoYPi4+PVr18/++WfQUFBxS7LO8PLy0v/+c9/rtjvnnvu0ejRo9WnTx/deuut2rlzp+bPn1/gj3StWrUUHBysGTNmqGLFiqpQoYKaNWtW6Jz45axZs0bTpk3TiBEj7JejzpkzR3fccYeef/55TZgwoUTjFWXHjh164IEH1KFDB7Vs2VKhoaH67bffNG/ePB05ckSTJ08usiwdERGhJ598Uq+88oruvfdetW/fXjt27NBnn32mypUru7Q606lTJ7Vu3VrPPfecfv75ZzVu3FgrV67Uhx9+qCFDhqhWrVpFvnbYsGF6++231b59ez355JP2yz9jYmIcEuOr0apVK/Xv319paWnavn277rrrLvn4+Gjv3r1avHixpkyZom7dul12jKefflpLlixR9+7d1bdvX8XFxen333/XsmXLNGPGDDVu3FgPPfSQ3n33XQ0YMEBr165VixYtlJeXpx9//FHvvvuu/d4UFzVs2FAJCQkOl39K0qhRo+x9Lq7zeO6559SzZ0/5+PioU6dOl60Cjh071n6/mCeeeELlypXTzJkzZbPZXPazCQ/hvgtG8NNPPxmPPvqoUaNGDcPX19eoWLGi0aJFC+P11183zp8/b++Xm5trjBo1yqhZs6bh4+NjVKtWzRg+fLhDH8P465Kzjh07FjjOpZcdFnX5p2EYxsqVK42GDRsavr6+Rt26dY3//e9/BS7/XL16tdG5c2cjOjra8PX1NaKjo41evXoZP/30U4FjXHqJ5Oeff260aNHC8Pf3NwIDA41OnToZP/zwg0Ofi8e79PLSSy9NLMrfL/8sSlGXfw4dOtSIiooy/P39jRYtWhjp6emFXrb54YcfGvXr1zfKlSvncJ6tWrUyGjRoUOgx/z7OqVOnjJiYGOPmm282cnNzHfqlpKQYXl5eRnp6+mXPobgyMzON8ePHG61atTKioqKMcuXKGSEhIUabNm2MJUuWOPQt7D2+cOGC8fzzzxuRkZGGv7+/0aZNG2P37t1GpUqVHC7pvPjaLVu2OIxZ1PezsO/T6dOnjZSUFCM6Otrw8fEx6tSpY0ycONHhskLDKHj5p2EYxnfffWe0atXK8PPzM6pUqWKMGTPGmD17doku/7zcJc0XzZo1y4iLizP8/f2NihUrGjfccIMxbNgw48iRIw7xFfa7aBiGcfLkSWPgwIFGlSpVDF9fX6Nq1apGUlKSceLECXufnJwc46WXXjIaNGhgWK1WIyQkxIiLizNGjRplZGdn2/tJMpKTk43//e9/Rp06dQyr1WrcdNNNxtq1awscd8yYMUaVKlUMLy8vh/fk4hiF2bZtm5GQkGAEBAQY5cuXN1q3bm189dVXDn2K+r6vXbvWkFRoLPAsFsNgJQyAksnKylJISIjGjh2r5557zt3h/GNZLBYlJyebMtUEFBdrJABcVmFPUL24ZqesPxYdgPlYIwHgshYtWqS5c+fab6e+ceNGLVy4UHfddVehz+8A8M9CIgHgsho1aqRy5cppwoQJOnXqlH0B5tixY90dGoAygDUSAADAaayRAAAATiORAAAATiORAAAATvPIxZafHi54+1kAUpsqCVfuBPzD+HmXN/0YljurumQcY9WvLhnHlahIAAAAp3lkRQIAgDLFhc+lKWtIJAAAMJsH1/9JJAAAMJsHVyQ8OEcCAABmoyIBAIDZPLcgQSIBAIDpmNoAAAAoiIoEAABm8+CP7SQSAACYjakNAACAgqhIAABgNs8tSJBIAABgOi/PzSSY2gAAAE6jIgEAgNk8tyBBIgEAgOk8+KoNEgkAAMzmuXkEayQAAIDzqEgAAGA2D75qg0QCAACzeW4ewdQGAABwHhUJAADMxlUbAADAaR68RoKpDQAA4DQqEgAAmM1zCxIkEgAAmM6D10gwtQEAAJxGRQIAALN5bkGCRAIAANN58FUbJBIAAJjNc/MI1kgAAADnUZEAAMBsHnzVBokEAABm8+D6vwefGgAAMBsVCQAAzMbUBgAAcJrn5hFMbQAAAOdRkQAAwGxMbQAAAKd5cP3fg08NAACYjYoEAABmY2oDAAA4zXPzCBIJAABM58FP/2SNBAAAcBoVCQAAzMYaCQAA4DTPzSOY2gAAAM6jIgEAgMksTG0AAABneXIiwdQGAAAeqEaNGrJYLAW25ORkSdL58+eVnJysSpUqKSAgQImJicrMzCzxcUgkAAAwmcXimq0ktmzZoqNHj9q3VatWSZK6d+8uSUpJSdFHH32kxYsXa/369Tpy5Ii6du1a4nNjagMAAJN5uWFqIywszOHr8ePHq1atWmrVqpWys7M1e/ZsLViwQG3atJEkzZkzR7Gxsdq0aZOaN29e7ONQkQAAwMPl5OTof//7n/r27SuLxaKtW7cqNzdX7dq1s/epV6+eqlevrvT09BKNTUUCAACTuWqxpc1mk81mc2izWq2yWq2Xfd3SpUuVlZWl3r17S5IyMjLk6+ur4OBgh34RERHKyMgoUUxUJAAAMFlhix6d2dLS0hQUFOSwpaWlXfH4s2fPVocOHRQdHe3yc6MiAQCAyVxVkRg+fLhSU1Md2q5UjTh06JA+//xzvf/++/a2yMhI5eTkKCsry6EqkZmZqcjIyBLFREUCAIBrhNVqVWBgoMN2pURizpw5Cg8PV8eOHe1tcXFx8vHx0erVq+1te/bs0eHDhxUfH1+imKhIAABgMnfdjyo/P19z5sxRUlKSypX7/3/yg4KC1K9fP6Wmpio0NFSBgYEaNGiQ4uPjS3TFhkQiAQCA6dx1Z8vPP/9chw8fVt++fQvsmzRpkry8vJSYmCibzaaEhARNmzatxMewGIZhuCLYsuTTwx+4OwSgTGpTJcHdIQBljp93edOPUeGZJi4Z5+xL37hkHFeiIgEAgMk8+VkbJBIAAJjMIs9NJLhqAwAAOI2KBAAAJmNqAwAAOM2D8wimNgAAgPOoSAAAYDJ3PEa8tJBIAABgMtZIAAAAp3lyIsEaCQAA4DQqEgAAmMyDCxIkEgAAmI2pDQAAgEJQkQAAwGSeXJEgkQAAwGSenEgwtQEAAJxGRQIAAJN5ckWCRAIAAJN5cB7B1AYAAHAeFQkAAEzG1AYAAHAaiQQAAHCaJz9GnDUSAADAaVQkAAAwmQcXJEgkAAAwmyevkWBqAwAAOI2KBK7alx9t0pcfbdLvmX9IkiJjIpTwr7aKvaWufs/4XWMemlDo65L+84BubNWoNEMFStXWb7Zq7lv/1e5dP+j48ROa9NqratOutX3/ubPnNHnSa1q7eq2ys7JVpUq0ev2rl3r07O7GqGEGizy3IkEigasWVDlQ9/Rrr7AqlWXI0JaV2zR7xH81dPpgRVQL06hFzzn0T//ka61dvEGxt9R1U8RA6fjz3J+qW/d6denaWamDhxbY//KEV7R50xaNe+lFRVeJVvqX6Ro3Jk3h4WG6o80dpR8wTOPJUxskErhqDePrO3zdsW+Cvvp4kw7tPqyoGhEKDK3osH/nl7t0Y6tGsvpbSzNMoNTddvttuu3224rcv/3bHerU5R41vaWJJKlbj0Qtefc9fb9zF4kErhluTSROnDiht956S+np6crIyJAkRUZG6tZbb1Xv3r0VFhbmzvDghPy8fG3fsFO28zmqUb96gf2//PSrftt/VImDupR+cEAZc+NNjbV+7Xp16dpF4eFh2rL5Gx36+ZCefrZg9QLXNioSJtiyZYsSEhJUvnx5tWvXTtdff70kKTMzU6+99prGjx+vFStWqEmTJu4KESVw5GCGpgyepgs5F+Tr76u+Ix5SZExEgX5fL/9GEdXDVbNBjBuiBMqWZ597RqNHjNFdrRNUrlw5WSwWjRj9vOKaxLk7NLiYB+cR7kskBg0apO7du2vGjBkFMjXDMDRgwAANGjRI6enplx3HZrPJZrM5tOXacuVj9XF5zChaeNXKemrGYJ0/e147vvheCyYu1sBXHnNIJnJsudq6ZrvuerCNGyMFyo6F/3tH3+3YqSlvTFZ0dJS2frNN48aMV1hYmJrf2tzd4QHF4rbLP3fs2KGUlJRCyz0Wi0UpKSnavn37FcdJS0tTUFCQw/butPdMiBiXU86nnMKqVFa166vqnn7tFX1dlDZ88KVDnx0bdirXlqumd97spiiBsuP8+fN6bfLreuqZobqjdStdX/d69XqwpxI63KV5c992d3hwMYvF4pKtLHJbIhEZGanNmzcXuX/z5s2KiChYGr/U8OHDlZ2d7bD1eCLRlaHCCYaRrws5Fxzavl6+RQ3iYxUQHOCmqICy48KFC7pw4UKBZzB4eXkrPz/fTVHBLJ6cSLhtauOpp57SY489pq1bt6pt27b2pCEzM1OrV6/Wm2++qZdffvmK41itVlmtjqv/fbKY1ihNH89ertim1yskPFjn/8zRtjXbtX/HQfVP62vvc/y3Ezqw82c9+mJv9wUKlLJzZ8/p8OFf7F//9ttv+nH3HgUFBSoqOkpNmsbp1Zcny+rnp6joKG3dslUfL/tYTz2T6saoYYaymgS4gtsSieTkZFWuXFmTJk3StGnTlJeXJ0ny9vZWXFyc5s6dqx49ergrPJTAmawzmj/hXZ36/bT8K/gpqmaU+qf1Vd24OvY+m5d/o6DKgQ5tgKfbtesHPdL7UfvXL7/0iiTp3i6dNGbcaL308nhNmfS6hg/7t05ln1JUdJQGPpms7vdzQypcOyyGYRjuDiI3N1cnTpyQJFWuXFk+PldXUfj08AeuCAvwOG2qJLg7BKDM8fMub/ox6k5q75Jx9qQsd8k4rlQmbkjl4+OjqKgod4cBAIApPHlqg4d2AQAAp5WJigQAAJ7MkysSJBIAAJjMkxMJpjYAAIDTqEgAAGAyDy5IkEgAAGA2pjYAAAAKQUUCAACTeXJFgkQCAACTkUgAAACneXAewRoJAADgPCoSAACYzJOnNqhIAABgNovFNVsJ/fbbb/rXv/6lSpUqyd/fXzfccIO++eYb+37DMPTCCy8oKipK/v7+ateunfbu3VuiY5BIAADggf744w+1aNFCPj4++uyzz/TDDz/olVdeUUhIiL3PhAkT9Nprr2nGjBn6+uuvVaFCBSUkJOj8+fPFPg5TGwAAmMwdUxsvvfSSqlWrpjlz5tjbatasaf+3YRiaPHmy/vOf/6hz586SpP/+97+KiIjQ0qVL1bNnz2Idh4oEAAAmc9XMhs1m06lTpxw2m81W6DGXLVumJk2aqHv37goPD9dNN92kN998077/4MGDysjIULt27extQUFBatasmdLT04t9biQSAABcI9LS0hQUFOSwpaWlFdr3wIEDmj59uurUqaMVK1bo8ccf1+DBgzVv3jxJUkZGhiQpIiLC4XURERH2fcXB1AYAACZz1dTG8OHDlZqa6tBmtVoL7Zufn68mTZpo3LhxkqSbbrpJ33//vWbMmKGkpCSXxCNRkQAAwHQWi8Ulm9VqVWBgoMNWVCIRFRWl+vXrO7TFxsbq8OHDkqTIyEhJUmZmpkOfzMxM+77iIJEAAMADtWjRQnv27HFo++mnnxQTEyPpr4WXkZGRWr16tX3/qVOn9PXXXys+Pr7Yx2FqAwAAk7njqo2UlBTdeuutGjdunHr06KHNmzdr1qxZmjVrlj2mIUOGaOzYsapTp45q1qyp559/XtHR0erSpUuxj0MiAQCAydxxY8umTZvqgw8+0PDhwzV69GjVrFlTkydP1oMPPmjvM2zYMJ09e1aPPfaYsrKydNttt2n58uXy8/Mr9nEshmEYZpyAO316+AN3hwCUSW2qJLg7BKDM8fMub/oxms3t7pJxvu692CXjuBJrJAAAgNOY2gAAwGSe/NAuEgkAAEzmyYkEUxsAAMBpVCQAADCZJ1ckSCQAADCZB+cRTG0AAADnUZEAAMBkTG0AAACneXIiwdQGAABwGhUJAABM5skVCRIJAABM5sF5BIkEAABm8+SKBGskAACA06hIAABgNg+uSJBIAABgMqY2AAAACkFFAgAAk3l5bkGCRAIAALMxtQEAAFAIKhIAAJjMy4MrEiQSAACYzJOnNkgkAAAwmSevI/DkcwMAACajIgEAgMlYIwEAAJzmyWskmNoAAABOoyIBAIDJmNoAAABOY2oDAACgEFQkAAAwmSd/aieRAADAZJ68RsKTkyQAAGAyKhIAAJjMkxdbkkgAAGAyT57aIJEAAMBknptGsEYCAABcBSoSAACYjKkNAADgNE9OJJjaAAAATqMiAQCAybj8EwAAOI2pDQAAgEJQkQAAwGSeW48oZiKxbNmyYg947733Oh0MAACeyJOnNoqVSHTp0qVYg1ksFuXl5V1NPAAA4BpSrEQiPz/f7DgAAPBY//iKBAAAcB6Xf17i7NmzWr9+vQ4fPqycnByHfYMHD3ZJYAAAeAoqEn/z7bff6u6779a5c+d09uxZhYaG6sSJEypfvrzCw8NJJAAA+Acp8X0kUlJS1KlTJ/3xxx/y9/fXpk2bdOjQIcXFxenll182I0YAAK5pFhdtJTFy5EhZLBaHrV69evb958+fV3JysipVqqSAgAAlJiYqMzOzxOdW4kRi+/btGjp0qLy8vOTt7S2bzaZq1appwoQJ+ve//13iAAAA8HReFotLtpJq0KCBjh49at82btxo35eSkqKPPvpIixcv1vr163XkyBF17dq1xMco8dSGj4+PvLz+yj/Cw8N1+PBhxcbGKigoSL/88kuJAwAAAOYoV66cIiMjC7RnZ2dr9uzZWrBggdq0aSNJmjNnjmJjY7Vp0yY1b968+McoaVA33XSTtmzZojp16qhVq1Z64YUXdOLECb399ttq2LBhSYcDAMDjuWqxpc1mk81mc2izWq2yWq2F9t+7d6+io6Pl5+en+Ph4paWlqXr16tq6datyc3PVrl07e9969eqpevXqSk9PL1EiUeKpjXHjxikqKkqS9OKLLyokJESPP/64jh8/rlmzZpV0OAAAPN6laxWc3dLS0hQUFOSwpaWlFXrMZs2aae7cuVq+fLmmT5+ugwcPqmXLljp9+rQyMjLk6+ur4OBgh9dEREQoIyOjROdW4opEkyZN7P8ODw/X8uXLSzoEAABwwvDhw5WamurQVlQ1okOHDvZ/N2rUSM2aNVNMTIzeffdd+fv7uywmbkgFAIDJXPWo7ctNY1xJcHCwrr/+eu3bt0933nmncnJylJWV5VCVyMzMLHRNxeWUOJGoWbPmZe/QdeDAgZIOCQCARysLd7Y8c+aM9u/fr4ceekhxcXHy8fHR6tWrlZiYKEnas2ePDh8+rPj4+BKNW+JEYsiQIQ5f5+bm6ttvv9Xy5cv19NNPl3Q4AABggqeeekqdOnVSTEyMjhw5ohEjRsjb21u9evVSUFCQ+vXrp9TUVIWGhiowMFCDBg1SfHx8iRZaSk4kEk8++WSh7W+88Ya++eabkg4HAIDHc8ctsn/99Vf16tVLJ0+eVFhYmG677TZt2rRJYWFhkqRJkybJy8tLiYmJstlsSkhI0LRp00p8HIthGIYrAj5w4IBuvPFGnTp1yhXDXZVPD3/g7hCAMqlNlQR3hwCUOX7e5U0/xtCNw1wyziu3TXDJOK7kssWWS5YsUWhoqKuGAwDAY5SFNRJmceqGVH9/QwzDUEZGho4fP+5USQQAAFy7SpxIdO7c2SGR8PLyUlhYmO644w6Hh4G4U8uoNu4OASiT/Ntf7+4QgDLHWPWr6cfwKvEjt64dJU4kRo4caUIYAAB4Lk+e2ijxPTK8vb117NixAu0nT56Ut7e3S4ICAADXhhJXJIq6yMNms8nX1/eqAwIAwNO44/LP0lLsROK1116T9Fd55v/+7/8UEBBg35eXl6cNGzaUmTUSAACUJRbWSPx14wrpr4rEjBkzHKYxfH19VaNGDc2YMcP1EQIAgDKr2InEwYMHJUmtW7fW+++/r5CQENOCAgDAk3jyYssSr5FYu3atGXEAAOCxPHmNRImv2khMTNRLL71UoH3ChAnq3r27S4ICAADXhhInEhs2bNDdd99doL1Dhw7asGGDS4ICAMCTWOTlkq0sKvHUxpkzZwq9zNPHx6dMPLALAICyhqmNv7nhhhu0aNGiAu3vvPOO6tev75KgAADwJBaLxSVbWVTiisTzzz+vrl27av/+/WrT5q9nWqxevVoLFizQkiVLXB4gAAAou0qcSHTq1ElLly7VuHHjtGTJEvn7+6tx48Zas2YNjxEHAKAQ3JDqEh07dlTHjh0lSadOndLChQv11FNPaevWrcrLy3NpgAAAXOtYI1GIDRs2KCkpSdHR0XrllVfUpk0bbdq0yZWxAQCAMq5EFYmMjAzNnTtXs2fP1qlTp9SjRw/ZbDYtXbqUhZYAABShrC6UdIViVyQ6deqkunXr6rvvvtPkyZN15MgRvf7662bGBgCAR/By0X9lUbErEp999pkGDx6sxx9/XHXq1DEzJgAAcI0odnqzceNGnT59WnFxcWrWrJmmTp2qEydOmBkbAAAewZPvI1HsRKJ58+Z68803dfToUfXv31/vvPOOoqOjlZ+fr1WrVun06dNmxgkAwDWLROJvKlSooL59+2rjxo3auXOnhg4dqvHjxys8PFz33nuvGTECAIAy6qpWbtStW1cTJkzQr7/+qoULF7oqJgAAPIprHtlVNisSTt2Q6lLe3t7q0qWLunTp4orhAADwKGV1WsIVXJJIAACAonFnSwAAgEJQkQAAwGQ8tAsAADjNy+K5EwCee2YAAMB0VCQAADAZV20AAACnefIaCaY2AACA06hIAABgMk++jwSJBAAAJmNqAwAAoBBUJAAAMBlTGwAAwGkWD74hFYkEAAAmY40EAABAIahIAABgMtZIAAAAp3nyLbKZ2gAAAE6jIgEAgMm8PHixJYkEAAAmY2oDAACgEFQkAAAwGTekAgAATvPkNRKemyIBAAC78ePHy2KxaMiQIfa28+fPKzk5WZUqVVJAQIASExOVmZlZonFJJAAAMJnFYnHJ5qwtW7Zo5syZatSokUN7SkqKPvroIy1evFjr16/XkSNH1LVr1xKNTSIBAIDJLC76zxlnzpzRgw8+qDfffFMhISH29uzsbM2ePVuvvvqq2rRpo7i4OM2ZM0dfffWVNm3aVOzxSSQAADCZqyoSNptNp06dcthsNttlj52cnKyOHTuqXbt2Du1bt25Vbm6uQ3u9evVUvXp1paenF/vcSCQAALhGpKWlKSgoyGFLS0srsv8777yjbdu2FdonIyNDvr6+Cg4OdmiPiIhQRkZGsWPiqg0AAEzmqqs2hg8frtTUVIc2q9VaaN9ffvlFTz75pFatWiU/Pz+XHL8wJBIAAJjMVfeRsFqtRSYOl9q6dauOHTumm2++2d6Wl5enDRs2aOrUqVqxYoVycnKUlZXlUJXIzMxUZGRksWMikQAAwAO1bdtWO3fudGjr06eP6tWrp2eeeUbVqlWTj4+PVq9ercTEREnSnj17dPjwYcXHxxf7OCQSAACYzNkrLq5GxYoV1bBhQ4e2ChUqqFKlSvb2fv36KTU1VaGhoQoMDNSgQYMUHx+v5s2bF/s4JBIAAJisrD60a9KkSfLy8lJiYqJsNpsSEhI0bdq0Eo1hMQzDMCk+tzmdm+3uEIAyKfDuBu4OAShzjFW/mn6MxQfmu2Sc7tc96JJxXImKBAAAJnPH1EZpIZEAAMBkZXVqwxW4IRUAAHAaFQkAAEzmyY8RJ5EAAMBknjy1QSIBAIDJLB68ksBzzwwAAJiOigQAACZjagMAADjNk+8jwdQGAABwGhUJAABM5sXUBgAAcBZTGwAAAIWgIgEAgMm4agMAADiNG1IBAAAUgooEAAAmY2oDAAA4jad/AgAAp3lyRYI1EgAAwGlUJAAAMJkn35CKRAIAAJMxtQEAAFAIKhIAAJjMk29IRSIBAIDJPPnpn56bIgEAANNRkQAAwGRctQEAAJzGVRsAAACFoCKBqzbnzbla+/la/XzwkKx+VjW68QYNShmkGjVj7H1sNpsmT5yilZ+tVE5Orpq3aK5n/zNMlSpXcmPkgHkOvp2uGpHVCrS/sWyuBr7+H10XFaOXH3tetzVsKquPr5Z/s06Dpj6vY1kn3BAtzObJUxtUJHDVtn2zTd17ddecBbP1xqzXdSE3TwMfG6Q/z/1p7/PqS5O0Yd0XGv9qmmbNnaETx4/r6SHPuDFqwFxNB3ZUZI+b7Fu7YT0lSYvXf6Lyfv5aOX6+DBlq8/T9ajHkPvmW89FHY+Z6dAn8n8xisbhkK4uoSOCqvT7zNYevR774gu68PUG7f9itm5vcrDOnz+jD95dp7IQxatqsqSRpxJgX1O3eHtq5Y6duaHyDO8IGTHUi+3eHr5/tmax9v/2s9d+l686421Ujoppuery9Tp87I0lKmpCiPz7YpTY3ttDqbze6I2SYyMuDP7d77pnBbc6c+et/jIFBQZKk3T/s1oULF9Ss+S32PjWuq6HIqEh9t2OnW2IESpNPOR/9q21XvbXiHUmS1cdXhgzZcnPsfc7n2pRv5Ou2hrcUNQxQJpXpROKXX35R3759L9vHZrPp1KlTDpvNZiulCHGp/Px8vTL+VTW+qbFq16klSTp54qR8fHxUMbCiQ9/QSqE6eeKkO8IESlWXWxMUHBCouSsXS5I27d6ms+fP6aVH/i1/q5/K+/nr5ceeVznvcooKDXdztDCDJ09tlOlE4vfff9e8efMu2yctLU1BQUEO2ysvvVpKEeJSL42doP37DmjcxLHuDgUoM/p16KnPNq/V0ZOZkv6a9ug+ZoA6NW+nM8t+UvbS3QoOCNTWn75TvpHv5mhhBouL/iuL3LpGYtmyZZfdf+DAgSuOMXz4cKWmpjq05Xidv6q44JyXXpyojes3ata8mYqIjLC3V6pcSbm5uTp96rRDVeL3k79z1QY8XvXwKmp3U0t1HfWoQ/uqrRtUO+k2VQoM0YW8PGWfPaWji7bpwLrDbooUcI5bE4kuXbrIYrHIMIwi+1yplGO1WmW1Wh3aTucWPR5czzAMTRj3statXqeZc6arStUqDvtj68eqXLly2vz1FrW9s40k6eeDh5RxNEONWGgJD9cn4X4dyzqhT75eXej+k6f+kCS1vvFWhQdX1rL0laUZHkpJWZ2WcAW3JhJRUVGaNm2aOnfuXOj+7du3Ky4urpSjQkm9NHaCln+6Qq+89rLKVyivEyf+ug4+ICBAfn5+CqgYoM5d79WkCZMVFBSoChUqaOK4l9Wo8Q1csQGPZrFY1Cehh+atWqK8/DyHfb0Temj34X06nnVS8fXjNOWJUZr0/pv66dcrV2Jx7Smr0xKu4NZEIi4uTlu3bi0ykbhStQJlw5JF70mS+vcZ4NA+YuwL6tTlHklS6jMp8vLy0rAhzyonN0fxtzbXM88PK/VYgdLU7uaWiomoqreWv1NgX92qtZTW91mFVgzWz5m/6sUFr2nSe2+6IUrg6lgMN/6l/uKLL3T27Fm1b9++0P1nz57VN998o1atWpVo3NO52a4ID/A4gXc3cHcIQJljrPrV9GN8c/xLl4zTJKyFS8ZxJbdWJFq2bHnZ/RUqVChxEgEAQJnjwWskyvTlnwAAoGzjFtkAAJiMxZYAAMBpXP4JAACc5skVCdZIAAAAp1GRAADAZJ5ckSCRAADAZJ68RoKpDQAA4DQqEgAAmMyTpzaoSAAAYDKLi/4rienTp6tRo0YKDAxUYGCg4uPj9dlnn9n3nz9/XsnJyapUqZICAgKUmJiozMzMEp8biQQAAB6oatWqGj9+vLZu3apvvvlGbdq0UefOnbVr1y5JUkpKij766CMtXrxY69ev15EjR9S1a9cSH8etD+0yCw/tAgrHQ7uAgkrjoV3f/7HNJeM0DLn5ql4fGhqqiRMnqlu3bgoLC9OCBQvUrVs3SdKPP/6o2NhYpaenq3nz5sUekzUSAACYzFVrJGw2m2w2m0Ob1WqV1Wq97Ovy8vK0ePFinT17VvHx8dq6datyc3PVrl07e5969eqpevXqJU4kmNoAAOAakZaWpqCgIIctLS2tyP47d+5UQECArFarBgwYoA8++ED169dXRkaGfH19FRwc7NA/IiJCGRkZJYqJigQAACZz1X0khg8frtTUVIe2y1Uj6tatq+3btys7O1tLlixRUlKS1q9f75JYLiKRAADAZK6a2ijONMbf+fr6qnbt2pKkuLg4bdmyRVOmTNH999+vnJwcZWVlOVQlMjMzFRkZWaKYmNoAAMBk7rj8szD5+fmy2WyKi4uTj4+PVq9ebd+3Z88eHT58WPHx8SUak4oEAAAeaPjw4erQoYOqV6+u06dPa8GCBVq3bp1WrFihoKAg9evXT6mpqQoNDVVgYKAGDRqk+Pj4Ei20lEgkAAAwnTuetXHs2DE9/PDDOnr0qIKCgtSoUSOtWLFCd955pyRp0qRJ8vLyUmJiomw2mxISEjRt2rQSH4f7SAD/INxHAiioNO4j8VP29y4Z5/qghi4Zx5VYIwEAAJzG1AYAACbz5Id2kUgAAGAyd6yRKC1MbQAAAKdRkQAAwHSeW5EgkQAAwGRMbQAAABSCigQAACbjqg0AAOA0EgkAAOA01kgAAAAUgooEAAAmY2oDAAA4zZMTCaY2AACA06hIAABgMk9ebEkiAQCAyZjaAAAAKAQVCQAATMbUBgAAcBpTGwAAAIWgIgEAgOk8tyJBIgEAgMk8N40gkQAAwHSevNiSNRIAAMBpVCQAADCd51YkSCQAADCZ56YRTG0AAICrQEUCAADTeW5NgkQCAACTcdUGAABAIUgkAACA05jaAADAZDy0CwAAoBBUJAAAMBkVCQAAgEJQkQAAwGRc/gkAAFAIEgkAAOA0pjYAADAZiy0BAAAKQUUCAADTeW5FgkQCAACTeW4awdQGAAC4ClQkAAAwmSffR4JEAgAA03luIsHUBgAAcBoVCQAATOa59QgSCQAASoHnphIkEgAAmMyTF1uyRgIAAA+Ulpampk2bqmLFigoPD1eXLl20Z88ehz7nz59XcnKyKlWqpICAACUmJiozM7NExyGRAADAA61fv17JycnatGmTVq1apdzcXN111106e/asvU9KSoo++ugjLV68WOvXr9eRI0fUtWvXEh3HYhiG4erg3e10bra7QwDKpMC7G7g7BKDMMVb9avoxTudmuWScij7BTr/2+PHjCg8P1/r163X77bcrOztbYWFhWrBggbp16yZJ+vHHHxUbG6v09HQ1b968WONSkQAA4B8gO/uvD9mhoaGSpK1btyo3N1ft2rWz96lXr56qV6+u9PT0Yo/LYksAAEznmsWWNptNNpvNoc1qtcpqtV72dfn5+RoyZIhatGihhg0bSpIyMjLk6+ur4OBgh74RERHKyMgodkxUJAAAMJnFRVtaWpqCgoIctrS0tCsePzk5Wd9//73eeecdl58bFQkAAK4Rw4cPV2pqqkPblaoRAwcO1Mcff6wNGzaoatWq9vbIyEjl5OQoKyvLoSqRmZmpyMjIYsdERQIAAJNZLBaXbFarVYGBgQ5bUYmEYRgaOHCgPvjgA61Zs0Y1a9Z02B8XFycfHx+tXr3a3rZnzx4dPnxY8fHxxT43KhIAAJiu9G9IlZycrAULFujDDz9UxYoV7esegoKC5O/vr6CgIPXr10+pqakKDQ1VYGCgBg0apPj4+GJfsSFx+Sfwj8Lln0BBpXH559kLp10yToVyFYvdt6i7ac6ZM0e9e/eW9NcNqYYOHaqFCxfKZrMpISFB06ZNK9HUBokE8A9CIgEUVBqJxDkXJRLlS5BIlBamNgAAMJ3nPmuDRAIAAJPx0C4AAIBCkEgAAACnMbUBAIDJLB68RoKKBAAAcJpHXv6JssFmsyktLU3Dhw+/4i1cgX8SfjfgSUgkYJpTp04pKChI2dnZCgwMdHc4QJnB7wY8CVMbAADAaSQSAADAaSQSAADAaSQSMI3VatWIESNYTAZcgt8NeBIWWwIAAKdRkQAAAE4jkQAAAE4jkQAAAE4jkQAAAE4jkYBp3njjDdWoUUN+fn5q1qyZNm/e7O6QALfasGGDOnXqpOjoaFksFi1dutTdIQFXjUQCpli0aJFSU1M1YsQIbdu2TY0bN1ZCQoKOHTvm7tAAtzl79qwaN26sN954w92hAC7D5Z8wRbNmzdS0aVNNnTpVkpSfn69q1app0KBBevbZZ90cHeB+FotFH3zwgbp06eLuUICrQkUCLpeTk6OtW7eqXbt29jYvLy+1a9dO6enpbowMAOBqJBJwuRMnTigvL08REREO7REREcrIyHBTVAAAM5BIAAAAp5FIwOUqV64sb29vZWZmOrRnZmYqMjLSTVEBAMxAIgGX8/X1VVxcnFavXm1vy8/P1+rVqxUfH+/GyAAArlbO3QHAM6WmpiopKUlNmjTRLbfcosmTJ+vs2bPq06ePu0MD3ObMmTPat2+f/euDBw9q+/btCg0NVfXq1d0YGeA8Lv+EaaZOnaqJEycqIyNDN954o1577TU1a9bM3WEBbrNu3Tq1bt26QHtSUpLmzp1b+gEBLkAiAQAAnMYaCQAA4DQSCQAA4DQSCQAA4DQSCQAA4DQSCQAA4DQSCQAA4DQSCQAA4DQSCcAD9e7dW126dLF/fccdd2jIkCGlHse6detksViUlZVV6scGUDpIJIBS1Lt3b1ksFlksFvn6+qp27doaPXq0Lly4YOpx33//fY0ZM6ZYffnjD6AkeNYGUMrat2+vOXPmyGaz6dNPP1VycrJ8fHw0fPhwh345OTny9fV1yTFDQ0NdMg4AXIqKBFDKrFarIiMjFRMTo8cff1zt2rXTsmXL7NMRL774oqKjo1W3bl1J0i+//KIePXooODhYoaGh6ty5s37++Wf7eHl5eUpNTVVwcLAqVaqkYcOG6dI73186tWGz2fTMM8+oWrVqslqtql27tmbPnq2ff/7Z/iyIkJAQWSwW9e7dW9JfT3BNS0tTzZo15e/vr8aNG2vJkiUOx/n00091/fXXy9/fX61bt3aIE4BnIpEA3Mzf3185OTmSpNWrV2vPnj1atWqVPv74Y+Xm5iohIUEVK1bUF198oS+//FIBAQFq3769/TWvvPKK5s6dq7feeksbN27U77//rg8++OCyx3z44Ye1cOFCvfbaa9q9e7dmzpypgIAAVatWTe+9954kac+ePTp69KimTJkiSUpLS9N///tfzZgxQ7t27VJKSor+9a9/af369ZL+Sni6du2qTp06afv27XrkkUf07LPPmvW2ASgrDAClJikpyejcubNhGIaRn59vrFq1yrBarcZTTz1lJCUlGREREYbNZrP3f/vtt426desa+fn59jabzWb4+/sbK1asMAzDMKKioowJEybY9+fm5hpVq1a1H8cwDKNVq1bGk08+aRiGYezZs8eQZKxatarQGNeuXWtIMv744w972/nz543y5csbX331lUPffv36Gb169TIMwzCGDx9u1K9f32H/M888U2AsAJ6FNRJAKfv4448VEBCg3Nxc5efn64EHHtDIkSOVnJysG264wWFdxI4dO7Rv3z5VrFjRYYzz589r//79ys7O1tGjRx0ez16uXDk1adKkwPTGRdu3b5e3t7datWpV7Jj37dunc+fO6c4773Roz8nJ0U033SRJ2r17d4HHxMfHxxf7GACuTSQSQClr3bq1pk+fLl9fX0VHR6tcuf//a1ihQgWHvmfOnFFcXJzmz59fYJywsDCnju/v71/i15w5c0aS9Mknn6hKlSoO+6xWq1NxAPAMJBJAKatQoYJq165drL4333yzFi1apPDwcAUGBhbaJyoqSl9//bVuv/12SdKFCxe0detW3XzzzYX2v+GGG5Sfn6/169erXbt2BfZfrIjk5eXZ2+rXry+r1arDhw8XWcmIjY3VsmXLHNo2bdp05ZMEcE1jsSVQhj344IOqXLmyOnfurC+++EIHDx7UunXrNHjwYP3666+SpCeffFLjx4/X0qVL9eOPP+qJJ5647D0gatSooaSkJPXt21dLly61j/nuu+9KkmJiYmSxWPTxxx/r+PHjOnPmjCpWrKinnnpKKSkpmjdvnvbv369t27bp9ddf17x58yRJAwYM0N69e/X0009rz549WrBggebOnWv2WwTAzUgkgDKsfPny2rBhg6pXr66uXbsqNjZW/fr10/nz5+0ViqFDh+qhhx5SUlKS4uPjVbFiRd13332XHXf69Onq1q2bnnjiCdWrV0+PPvqozp49K0mqUqWKRo0apWeffVYREREaOHCgJGnMmDF6/vnnlZaWptjYWLVv316ffPKJatasKUmqXr263nvvPS1dulSNGzfWjBkzNG7cOBPfHQBlgcUoakUWAADAFVCRAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATiORAAAATvt/8HxdlxRpMvoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test with different hyperparameters"
      ],
      "metadata": {
        "id": "RQ9fOTRbuu5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_s.shape[1]\n",
        "sigmoid_perceptron = SigmoidPerceptron(input_size, learning_rate=0.01, epochs=1000, lambda_=0.0001)\n",
        "sigmoid_perceptron.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_prob = sigmoid_perceptron.predict(X_test_s)\n",
        "y_pred_sigmoid = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "\n",
        "accuracy_sigmoid = accuracy_score(y_test_s, y_pred_sigmoid)\n",
        "print(f'\\nTest Accuracy with Sigmoid Perceptron: {accuracy_sigmoid * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_sigmoid, target_names=['0 (Non-Diabetic)', '1 (Diabetic)']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzhlF4bgS7cd",
        "outputId": "34e9f05c-b40d-4f98-8bcf-e2939b335c0d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000, Loss: 0.6016, Training Accuracy: 76.06%\n",
            "Epoch 200/1000, Loss: 0.5572, Training Accuracy: 76.55%\n",
            "Epoch 300/1000, Loss: 0.5316, Training Accuracy: 76.22%\n",
            "Epoch 400/1000, Loss: 0.5154, Training Accuracy: 76.38%\n",
            "Epoch 500/1000, Loss: 0.5044, Training Accuracy: 76.22%\n",
            "Epoch 600/1000, Loss: 0.4965, Training Accuracy: 76.38%\n",
            "Epoch 700/1000, Loss: 0.4907, Training Accuracy: 76.38%\n",
            "Epoch 800/1000, Loss: 0.4863, Training Accuracy: 76.55%\n",
            "Epoch 900/1000, Loss: 0.4829, Training Accuracy: 76.87%\n",
            "Epoch 1000/1000, Loss: 0.4802, Training Accuracy: 76.87%\n",
            "\n",
            "Test Accuracy with Sigmoid Perceptron: 73.38%\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "0 (Non-Diabetic)       0.62      0.64      0.63        55\n",
            "    1 (Diabetic)       0.80      0.79      0.79        99\n",
            "\n",
            "        accuracy                           0.73       154\n",
            "       macro avg       0.71      0.71      0.71       154\n",
            "    weighted avg       0.73      0.73      0.73       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_s.shape[1]\n",
        "sigmoid_perceptron = SigmoidPerceptron(input_size, learning_rate=0.001, epochs=1000, lambda_=0.001)\n",
        "sigmoid_perceptron.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_prob = sigmoid_perceptron.predict(X_test_s)\n",
        "y_pred_sigmoid = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "\n",
        "accuracy_sigmoid = accuracy_score(y_test_s, y_pred_sigmoid)\n",
        "print(f'\\nTest Accuracy with Sigmoid Perceptron: {accuracy_sigmoid * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_sigmoid, target_names=['0 (Non-Diabetic)', '1 (Diabetic)']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHP-xnHXu3-7",
        "outputId": "c8e04360-b889-4de6-d288-545aa8cd0719"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000, Loss: 0.6857, Training Accuracy: 67.75%\n",
            "Epoch 200/1000, Loss: 0.6738, Training Accuracy: 72.96%\n",
            "Epoch 300/1000, Loss: 0.6629, Training Accuracy: 74.43%\n",
            "Epoch 400/1000, Loss: 0.6527, Training Accuracy: 75.08%\n",
            "Epoch 500/1000, Loss: 0.6433, Training Accuracy: 75.41%\n",
            "Epoch 600/1000, Loss: 0.6346, Training Accuracy: 75.24%\n",
            "Epoch 700/1000, Loss: 0.6266, Training Accuracy: 75.57%\n",
            "Epoch 800/1000, Loss: 0.6191, Training Accuracy: 75.57%\n",
            "Epoch 900/1000, Loss: 0.6121, Training Accuracy: 75.90%\n",
            "Epoch 1000/1000, Loss: 0.6056, Training Accuracy: 75.90%\n",
            "\n",
            "Test Accuracy with Sigmoid Perceptron: 70.78%\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "0 (Non-Diabetic)       0.59      0.62      0.60        55\n",
            "    1 (Diabetic)       0.78      0.76      0.77        99\n",
            "\n",
            "        accuracy                           0.71       154\n",
            "       macro avg       0.68      0.69      0.69       154\n",
            "    weighted avg       0.71      0.71      0.71       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_s.shape[1]\n",
        "sigmoid_perceptron = SigmoidPerceptron(input_size, learning_rate=0.01, epochs=10000, lambda_=0.0001)\n",
        "sigmoid_perceptron.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_prob = sigmoid_perceptron.predict(X_test_s)\n",
        "y_pred_sigmoid = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "\n",
        "accuracy_sigmoid = accuracy_score(y_test_s, y_pred_sigmoid)\n",
        "print(f'\\nTest Accuracy with Sigmoid Perceptron: {accuracy_sigmoid * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_sigmoid, target_names=['0 (Non-Diabetic)', '1 (Diabetic)']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsphDuvou6fn",
        "outputId": "46762d6a-f110-48b6-dad9-e38f17104f2f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/10000, Loss: 0.6021, Training Accuracy: 76.22%\n",
            "Epoch 200/10000, Loss: 0.5572, Training Accuracy: 76.55%\n",
            "Epoch 300/10000, Loss: 0.5315, Training Accuracy: 76.22%\n",
            "Epoch 400/10000, Loss: 0.5153, Training Accuracy: 76.22%\n",
            "Epoch 500/10000, Loss: 0.5043, Training Accuracy: 76.38%\n",
            "Epoch 600/10000, Loss: 0.4964, Training Accuracy: 76.38%\n",
            "Epoch 700/10000, Loss: 0.4907, Training Accuracy: 76.55%\n",
            "Epoch 800/10000, Loss: 0.4863, Training Accuracy: 76.38%\n",
            "Epoch 900/10000, Loss: 0.4829, Training Accuracy: 76.71%\n",
            "Epoch 1000/10000, Loss: 0.4802, Training Accuracy: 77.04%\n",
            "Epoch 1100/10000, Loss: 0.4781, Training Accuracy: 76.87%\n",
            "Epoch 1200/10000, Loss: 0.4764, Training Accuracy: 77.04%\n",
            "Epoch 1300/10000, Loss: 0.4750, Training Accuracy: 76.55%\n",
            "Epoch 1400/10000, Loss: 0.4739, Training Accuracy: 76.55%\n",
            "Epoch 1500/10000, Loss: 0.4729, Training Accuracy: 76.55%\n",
            "Epoch 1600/10000, Loss: 0.4722, Training Accuracy: 76.55%\n",
            "Epoch 1700/10000, Loss: 0.4715, Training Accuracy: 76.55%\n",
            "Epoch 1800/10000, Loss: 0.4710, Training Accuracy: 76.55%\n",
            "Epoch 1900/10000, Loss: 0.4705, Training Accuracy: 76.38%\n",
            "Epoch 2000/10000, Loss: 0.4701, Training Accuracy: 76.55%\n",
            "Epoch 2100/10000, Loss: 0.4698, Training Accuracy: 76.55%\n",
            "Epoch 2200/10000, Loss: 0.4695, Training Accuracy: 76.55%\n",
            "Epoch 2300/10000, Loss: 0.4693, Training Accuracy: 76.71%\n",
            "Epoch 2400/10000, Loss: 0.4691, Training Accuracy: 76.71%\n",
            "Epoch 2500/10000, Loss: 0.4689, Training Accuracy: 76.71%\n",
            "Epoch 2600/10000, Loss: 0.4688, Training Accuracy: 76.55%\n",
            "Epoch 2700/10000, Loss: 0.4686, Training Accuracy: 76.55%\n",
            "Epoch 2800/10000, Loss: 0.4685, Training Accuracy: 76.71%\n",
            "Epoch 2900/10000, Loss: 0.4684, Training Accuracy: 76.71%\n",
            "Epoch 3000/10000, Loss: 0.4684, Training Accuracy: 76.71%\n",
            "Epoch 3100/10000, Loss: 0.4683, Training Accuracy: 76.71%\n",
            "Epoch 3200/10000, Loss: 0.4682, Training Accuracy: 76.71%\n",
            "Epoch 3300/10000, Loss: 0.4682, Training Accuracy: 76.71%\n",
            "Epoch 3400/10000, Loss: 0.4681, Training Accuracy: 76.71%\n",
            "Epoch 3500/10000, Loss: 0.4681, Training Accuracy: 76.71%\n",
            "Epoch 3600/10000, Loss: 0.4681, Training Accuracy: 76.87%\n",
            "Epoch 3700/10000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 3800/10000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 3900/10000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4000/10000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4100/10000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4200/10000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4300/10000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4400/10000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4500/10000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4600/10000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4700/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 4800/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 4900/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5000/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5100/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5200/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5300/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5400/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5500/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5600/10000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5700/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 5800/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 5900/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6000/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6100/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6200/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6300/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6400/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6500/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6600/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6700/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6800/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6900/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7000/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7100/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7200/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7300/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7400/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7500/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7600/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7700/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7800/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7900/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8000/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8100/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8200/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8300/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8400/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8500/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8600/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8700/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8800/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8900/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9000/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9100/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9200/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9300/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9400/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9500/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9600/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9700/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9800/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9900/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10000/10000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "\n",
            "Test Accuracy with Sigmoid Perceptron: 75.32%\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "0 (Non-Diabetic)       0.65      0.67      0.66        55\n",
            "    1 (Diabetic)       0.81      0.80      0.81        99\n",
            "\n",
            "        accuracy                           0.75       154\n",
            "       macro avg       0.73      0.74      0.73       154\n",
            "    weighted avg       0.76      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_s.shape[1]\n",
        "sigmoid_perceptron = SigmoidPerceptron(input_size, learning_rate=0.01, epochs=100000, lambda_=0.001)\n",
        "sigmoid_perceptron.fit(X_train_s, y_train_s)\n",
        "\n",
        "y_pred_prob = sigmoid_perceptron.predict(X_test_s)\n",
        "y_pred_sigmoid = np.where(y_pred_prob >= 0.5, 1, 0)\n",
        "\n",
        "accuracy_sigmoid = accuracy_score(y_test_s, y_pred_sigmoid)\n",
        "print(f'\\nTest Accuracy with Sigmoid Perceptron: {accuracy_sigmoid * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_s, y_pred_sigmoid, target_names=['0 (Non-Diabetic)', '1 (Diabetic)']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVtSJ5QLu8vW",
        "outputId": "003ad1af-96cd-4d79-912a-1607c782cc06"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100000, Loss: 0.6033, Training Accuracy: 75.57%\n",
            "Epoch 200/100000, Loss: 0.5579, Training Accuracy: 76.22%\n",
            "Epoch 300/100000, Loss: 0.5320, Training Accuracy: 76.22%\n",
            "Epoch 400/100000, Loss: 0.5156, Training Accuracy: 76.55%\n",
            "Epoch 500/100000, Loss: 0.5045, Training Accuracy: 76.22%\n",
            "Epoch 600/100000, Loss: 0.4966, Training Accuracy: 76.38%\n",
            "Epoch 700/100000, Loss: 0.4907, Training Accuracy: 76.38%\n",
            "Epoch 800/100000, Loss: 0.4863, Training Accuracy: 76.55%\n",
            "Epoch 900/100000, Loss: 0.4829, Training Accuracy: 76.87%\n",
            "Epoch 1000/100000, Loss: 0.4802, Training Accuracy: 76.71%\n",
            "Epoch 1100/100000, Loss: 0.4781, Training Accuracy: 76.71%\n",
            "Epoch 1200/100000, Loss: 0.4764, Training Accuracy: 76.71%\n",
            "Epoch 1300/100000, Loss: 0.4750, Training Accuracy: 77.04%\n",
            "Epoch 1400/100000, Loss: 0.4738, Training Accuracy: 76.55%\n",
            "Epoch 1500/100000, Loss: 0.4729, Training Accuracy: 76.55%\n",
            "Epoch 1600/100000, Loss: 0.4721, Training Accuracy: 76.38%\n",
            "Epoch 1700/100000, Loss: 0.4715, Training Accuracy: 76.38%\n",
            "Epoch 1800/100000, Loss: 0.4709, Training Accuracy: 76.55%\n",
            "Epoch 1900/100000, Loss: 0.4705, Training Accuracy: 76.38%\n",
            "Epoch 2000/100000, Loss: 0.4701, Training Accuracy: 76.55%\n",
            "Epoch 2100/100000, Loss: 0.4698, Training Accuracy: 76.55%\n",
            "Epoch 2200/100000, Loss: 0.4695, Training Accuracy: 76.71%\n",
            "Epoch 2300/100000, Loss: 0.4693, Training Accuracy: 76.71%\n",
            "Epoch 2400/100000, Loss: 0.4691, Training Accuracy: 76.71%\n",
            "Epoch 2500/100000, Loss: 0.4689, Training Accuracy: 76.71%\n",
            "Epoch 2600/100000, Loss: 0.4688, Training Accuracy: 76.55%\n",
            "Epoch 2700/100000, Loss: 0.4686, Training Accuracy: 76.55%\n",
            "Epoch 2800/100000, Loss: 0.4685, Training Accuracy: 76.71%\n",
            "Epoch 2900/100000, Loss: 0.4684, Training Accuracy: 76.71%\n",
            "Epoch 3000/100000, Loss: 0.4684, Training Accuracy: 76.71%\n",
            "Epoch 3100/100000, Loss: 0.4683, Training Accuracy: 76.71%\n",
            "Epoch 3200/100000, Loss: 0.4682, Training Accuracy: 76.71%\n",
            "Epoch 3300/100000, Loss: 0.4682, Training Accuracy: 76.71%\n",
            "Epoch 3400/100000, Loss: 0.4681, Training Accuracy: 76.71%\n",
            "Epoch 3500/100000, Loss: 0.4681, Training Accuracy: 76.71%\n",
            "Epoch 3600/100000, Loss: 0.4681, Training Accuracy: 76.87%\n",
            "Epoch 3700/100000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 3800/100000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 3900/100000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4000/100000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4100/100000, Loss: 0.4680, Training Accuracy: 76.87%\n",
            "Epoch 4200/100000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4300/100000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4400/100000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4500/100000, Loss: 0.4679, Training Accuracy: 76.87%\n",
            "Epoch 4600/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 4700/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 4800/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 4900/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5000/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5100/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5200/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5300/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5400/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5500/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5600/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5700/100000, Loss: 0.4679, Training Accuracy: 77.04%\n",
            "Epoch 5800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 5900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 6900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 7900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 8900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 9900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 10900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 11900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 12900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 13900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 14900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 15900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 16900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 17900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 18900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 19900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 20900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 21900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 22900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 23900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 24900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 25900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 26900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 27900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 28900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 29900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 30900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 31900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 32900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 33900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 34900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 35900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 36900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 37900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 38900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 39900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 40900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 41900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 42900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 43900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 44900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 45900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 46900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 47900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 48900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 49900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 50900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 51900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 52900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 53900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 54900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 55900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 56900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 57900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 58900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 59900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 60900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 61900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 62900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 63900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 64900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 65900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 66900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 67900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 68900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 69900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 70900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 71900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 72900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 73900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 74900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 75900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 76900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 77900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 78900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 79900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 80900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 81900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 82900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 83900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 84900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 85900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 86900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 87900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 88900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 89900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 90900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 91900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 92900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 93900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 94900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 95900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 96900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 97900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 98900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99100/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99200/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99300/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99400/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99500/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99600/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99700/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99800/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 99900/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "Epoch 100000/100000, Loss: 0.4678, Training Accuracy: 77.04%\n",
            "\n",
            "Test Accuracy with Sigmoid Perceptron: 75.32%\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "0 (Non-Diabetic)       0.65      0.67      0.66        55\n",
            "    1 (Diabetic)       0.81      0.80      0.81        99\n",
            "\n",
            "        accuracy                           0.75       154\n",
            "       macro avg       0.73      0.74      0.73       154\n",
            "    weighted avg       0.76      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    }
  ]
}